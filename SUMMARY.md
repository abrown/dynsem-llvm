Project Summary
===============

This project began with the stated goal to build a generator for low-level Dynsem interpreters to compare its performance against the actual Java-based Dynsem implementation. The hypothesis was that LLVM might have features (i.e. JIT) providing exceptionally fast performance due to their low-level nature. Bottom line up front: the LLVM JIT did not seem to offer great performance advantages (e.g. http://stackoverflow.com/questions/6833068) and building the interpreter generator was a difficult enough task so this initial implementation abandoned the LLVM work and focused on the latter task. In any case, since the goal was largely an optimization and "premature optimization is the root of all evil," it seemed wise to implement a working, high-level version first and then profile it to focus on the hot spots.

My initial attempts at programming even a simple interpreter in pure LLVM were insightful but inefficient. The absence of higher-level abstractions and my inexperience with LLVM made the programming painfully slow. Switching to C, however, allowed me to implement a sample interpreter that performed the essential functions of a Dynsem interpreter: _match_ a given term against a set of rules, _transform_ the term using a matching rule, and _repeat_ until matching fails. 

Dynsem rules look like `t1 -> t2 where ps`; this means that if the current program matches a term `t1` as well as its optional premises `ps`, the interpreter will instantiate and return `t2`. For example, given the rule `a(b(x)) -> x` and a program `a(b(42))`, the interpreter would reduce this program to `42`. Dynsem has other features, such as signatures and semantic components, but these were not planned for this project. 

With a sample C interpreter in hand, it was easier to generalize into an interpreter generator. Since the term structures were C-based, the generator functions were programmed in C; in hindsight, a higher-level language would have been a faster choice (perhaps C++ since it has an LLVM API) but using C did make it easy to integrate with the libraries used in the project: _aterms_, _bison/flex_, and _cii_. There was no requirement, however, that the generated interpreter and the generator be the same language but this happened naturally throughout the course of the project.

Dr. Tolmach encouraged the use of the _aterms_ library since it simplified matching and cloning terms. Recall that the essential functions of Dynsem are to _match_ and _transform_ terms, so this library contributed a good deal of value. The only complaints, really, were that it required a rather large build environment (i.e. see `meta-env` in README) to install and that it had no way to match terms over a decision tree (e.g. with similar rules like `a(1)` and `a(2)`, we wanted to avoid matching each term separately but instead match `a` and then decide between `1` and `2`). The `aterms` library used hash consing to test equality and for maximal subterm sharing and managed the memory and garbage collection for all of this; building an alternative solution seemed daunting. The alternative, to deep clone the required structures and modify the program in place, was used for the initial implementation but the built-in memory management and garbage collection of _aterms_ was attractive. Interesting future work would be to find some typical programs and performance test both approaches against each other.

The other libraries provided necessary functionality but were less central to the project focus. The _bison/flex_ tools provided lexing and parsing of Dynsem specifications (a subset of features); the applicable files are found under `src/dynsem.y` and `src/dynsem.l`. Since C was used as the generation language, it lacked built-in features that were conveniently provided by Dr. Hanson's _cii_ library (developed during the writing of "C Interfaces and Implementations: Techniques for Creating Reusable Software"). For example, before generation the rules were dynamically stored in a list provided by _cii_ and after generation in a statically allocated rule table.

Building the generator identified areas of future work. The generator successfully parsed Dynsem specifications containing rules, premises, and native functions; however, much of the project time was spent on infrastructure: figuring out how to install LLVM/Clang, learning to use LLVM (and _aterms_ and _bison_), building makefiles and tests for the generator. But other tasks seemed interesting for future work:
 - _Improve the infrastructure_: figure out how to build and install all requirements inside Docker (or at least in a `3rd` party directory instead of at the OS level), use a templating library instead of `puts`/`fprintf` (e.g. `mustach`), switch to C++ for generation
 - _Profile the generated code_: determine some common programs to run against (harder than it seems), find hot spots and replace with generated LLVM IR (perhaps even JIT-ed code?), generate matching trees either by modifying _aterms_ or directly using LLVM, performance test against the Java Dynsem implementation.
 - _Add more Dynsem features_: add semantic components, add better native support (e.g. system libraries), add signatures.
